conv1 = TimeDistributed(Convolution2D(5, 3, 3, activation='relu', border_mode='same', W_regularizer=l2(1)))
        max1 = TimeDistributed(MaxPooling2D((3, 3), strides=(2, 2)))
        conv2 = TimeDistributed(Convolution2D(10, 3, 3, activation='relu', border_mode='same', W_regularizer=l2(1)))
        max2 = TimeDistributed(MaxPooling2D((3, 3), strides=(2, 2)))
        conv3 = TimeDistributed(Convolution2D(20, 3, 3, activation='relu', border_mode='same', W_regularizer=l2(1)))
        max3 = TimeDistributed(MaxPooling2D((3, 3), strides=(2, 2)))

        v = []
        pred_list = []
        for i in range(self.number_of_views):
            v.append(conv1(input_list[i]))
            v[i] = max1(v[i])
            v[i] = conv2(v[i])
            v[i] = max2(v[i])
            v[i] = conv3(v[i])
            v[i] = max3(v[i])

            v[i] = TimeDistributed(Dropout(0.5))(v[i])
            v[i] = TimeDistributed(Convolution2D(30, 3, 3, activation='relu', border_mode='same', W_regularizer=l2(1)))(v[i])
            v[i] = TimeDistributed(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))(v[i])
            v[i] = TimeDistributed(Convolution2D(30, 3, 3, activation='relu', border_mode='same', W_regularizer=l2(1)))(v[i])
            v[i] = TimeDistributed(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))(v[i])
            v[i] = TimeDistributed(Flatten())(v[i])

            v[i] = TimeDistributed(Dense(128, activation='relu'))(v[i])
            v[i] = TimeDistributed(Dropout(0.5))(v[i])
            v[i] = LSTM(output_dim=1, name='pred'+str(i), activation='linear')(v[i])
            pred_list.append(v[i])



m = {
            'model_variant': '7view_keras',
            'batch_size': 36,

            # SGD
            'base_lr': 0.001,
            'stepsize': '1000',
            'gamma': '0.5',
            'max_iter': '1000000',
            'momentum': 0.95,
            'weight_decay': 0.05,
            'regularization_type': '\'"L2\"',
            'lr_policy': '\"step\"',    # caffe

            # solver
            'solver_mode': 'GPU',
            'type': '\"AdaGrad\"',      # caffe

            # display
            'display': '100',           # caffe
            'display_iter': 1,

            # snapshot parameters
            'snapshot_fld': self.snapshot_dir,
            'model_fld': self.model_dir,
            'snapshot_approach': ['best', 'last'],  # 'last', 'best', 'step'
            'snapshot_epochs': 1,  # only used if 'step' is included in snapshot approach
            'caffe_solver_state_epochs': 1000,  # only used if 'step' is included in snapshot approach; handled by caffe
            'snapshot_str': self.__class__.__name__,  # update snapshot_str in the external metadata or here to whatever

            #validation
            'test_interval': 1,
            'test_approach': 'epoch',  # 'epoch', 'iter', 'none'; by setting as 'epoch', 'test_interval' is ignored

            # data handler parameters
            'resize_width': 200,
            'resize_height': 200,
            'crop_width': 200,
            'crop_height': 200,
            'channels': 1,
            'random_translate_std_ratio': 20,
            'random_rotate_degree': 7,
            'train_batch_method': 'random',  # 'random', 'uniform'
            'split_ratio': 0.1,  # set to 0 if not splitting train and valid
            'load_to_memory': True,
            'subtract_mean': False,
            'file_format': 'mat',  # 'mat', 'image'
            'delimiter': ',',
            'main_label_index': 0,
            'label_type': 'single_value',  # 'single_value', 'mask_image'
            'scale_label': 1,  # 0: do not rescale, else: rescale all labels to the value

            # end of training parameters
            'max_epoch': 150,
            'min_epoch': 50,
            'terminate_if_not_improved_epoch': 10,
            'averaging_window': 15,

            #cine
            'num_frames': 25

        }


